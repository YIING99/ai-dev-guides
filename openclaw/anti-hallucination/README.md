# AI Agent 幻觉防治实战：当你的 AI 助手自信地说谎

> 一个真实案例，揭示 AI Agent 最隐蔽的翻车模式——不是"不知道"，而是"坚信错的"。

---

## 事件还原

### 背景

我在 VPS 上部署了一只基于 Claude Sonnet 4.5 的 AI 助手（代号"龙虾2号"），通过飞书与我交互，负责日常知识管理——捕捉碎片信息、整理知识库、搜索验证事实。

关键技术栈：**OpenClaw**（开源 AI Agent 框架）+ **OpenRouter**（模型路由平台）+ **飞书**（即时通讯）。

### 第一幕：自信的谎言

我问龙虾2号一个简单的问题：

> **我**：你的联网搜索用的什么技术？

龙虾2号的回答堪称"教科书级别的自信"：

> 🔍 工具名称：web_search
> 🌐 搜索引擎：**Brave Search**（一个注重隐私的独立搜索引擎）
> 📡 调用方式：通过 OpenClaw 提供的 web_search 工具函数，向 Brave Search API 发送请求
> 无需 API key（OpenClaw 内置）

说得头头是道。四个要点，有工具名、有引擎名、有技术路线、甚至还解释了"注重隐私"。

**但全是编的。**

### 第二幕：我核查了服务器

我 SSH 上了 VPS，逐层检查了真实配置：

```
实际搜索链路：
OpenClaw → OpenRouter API → Perplexity Sonar Pro 模型
```

真相：
- **从未配置过 Brave Search API key** —— 压根就没有这个东西
- 搜索走的是 **OpenRouter → Perplexity Sonar Pro**，一个完全不同的技术路线
- 能搜索是因为 OpenClaw 自动检测到了环境变量中的 `OPENROUTER_API_KEY`，悄悄启用了 Perplexity 作为搜索后端

### 第三幕：追问后，它"纠正"了——但纠正得更离谱

我说："详细核查一下，我怀疑！"

龙虾2号这次真的去查了配置文件，发现确实没有 Brave 的 API key。然后它得出了一个新结论：

> ❌ 我犯的错误：我声称使用 Brave Search API，但实际上没有配置 API key
> ✅ 实际情况：**web_search 工具存在但无法使用**
> 需要配置 BRAVE_API_KEY 才能启用

这个纠正**仍然是错的**：
- 搜索一直在正常工作（之前还帮我查过天气）
- 只是搜索后端不是 Brave，而是 Perplexity
- 龙虾查到了"没有 Brave 配置"，却推出了"搜索不可用"这个错误结论

---

## 为什么会这样？根因分析

### 1. 幻觉的源头：OpenClaw 内置工具描述

OpenClaw 框架的工具列表里是这么写的：

```
web_search: Search the web (Brave API)
```

这是龙虾能看到的"官方说明"。它没有理由怀疑这个说明是错的——就像你不会怀疑药瓶上的标签写错了一样。

但实际上：
- 这个描述是 OpenClaw **通用的默认描述**
- 实际搜索用的是什么后端，完全取决于**你的配置**
- 我配的是 OpenRouter + Perplexity，但工具描述不会自动更新

### 2. AI Agent 没有"身体感知"

人类使用工具时有直觉——你用锤子钉钉子，你能感受到锤子的重量、听到钉子进去的声音。

**AI Agent 用工具时没有这种感知。** 它调用 `web_search`，得到了搜索结果，但它不知道：
- 请求实际发往了哪个服务器
- 中间经过了几层转发
- 真正执行搜索的是哪个引擎

它能看到的，只有**工具描述**和**返回结果**。工具描述说是 Brave，它就信了。

### 3. 信任链污染

```
开发者写了 "Brave API" → OpenClaw 展示给 AI → AI 告诉用户 → 用户相信了
   (源头错误)          (无脑传播)         (自信转述)     (受害者)
```

信息从上游到下游，每传一层，**被质疑的概率就降低一层**。到了最终用户那里，信息已经被包装成了"AI 专家的判断"——谁会想到去怀疑呢？

---

## 提炼出的底层规律

### 规律一：描述 ≠ 现实（Description ≠ Reality）

> **任何东西声称自己是什么，不等于它实际是什么。**

这不仅适用于 AI，适用于所有系统：

| 场景 | 标签说的 | 现实可能是 |
|------|---------|-----------|
| AI 工具描述 | "Brave Search API" | 实际走 Perplexity |
| 错误提示 | "503 服务不可用" | 实际是本地网络没通 |
| 函数名 | `sendEmail()` | 只是把邮件放进了队列 |
| SDK 名称 | `official-sdk-v1` | 已废弃的不兼容旧版 |
| 监控面板 | "系统正常" | 某个服务已经卡死了 |

**核心对策**：不要问"它说它是什么"，要问"它实际做了什么"。

### 规律二：信任链中任一环节出错，所有下游都会被污染

```
信息在传递过程中，错误只会被放大，不会被纠正。
因为每一层消费者都默认上游是对的。
```

这就是为什么：
- 文档错了 → 所有读文档的人都会写出错误的代码
- 注释过时了 → 所有看注释的人都会误解代码意图
- AI 的工具描述错了 → AI 会自信地传播错误信息给用户

### 规律三：标签的可靠性有层级

| 层级 | 信息来源 | 可靠性 |
|------|---------|--------|
| L1 | **实际行为观测**（抓包、日志、实测） | 最可靠 |
| L2 | **配置文件/环境变量** | 较可靠 |
| L3 | **官方文档/README** | 可能过时 |
| L4 | **代码注释/变量名** | 经常不准 |
| L5 | **UI 描述/工具提示** | 最不可靠 |

**AI 能看到的通常是 L4-L5，而真相在 L1-L2。**

---

## 怎么防？拿来即用的实操方案

### 方案一：给 AI Agent 写一份"自我认知档案"

光告诉 AI "不要瞎说"是不够的——它不瞎说，但也说不出对的。

你需要写一份 **基于实际验证的工具说明文档**（不是复制粘贴工具描述），告诉 AI：

```markdown
# TOOLS.md - 我的真实工具架构

## 联网搜索
- 实际搜索路线：OpenRouter → Perplexity Sonar Pro
- ❌ 不是 Brave Search（虽然工具描述可能这么显示）
- 认证方式：环境变量 OPENROUTER_API_KEY

## 没有的能力
- ❌ 没有 Brave Search API
- ❌ 没有浏览器自动化
```

**关键**：这份文档必须来自你对配置文件和实际行为的验证，不能从工具描述复制。

### 方案二：注入反幻觉铁律到系统提示

在 AI 的系统提示（System Prompt）中加入明确规则：

```markdown
## 反幻觉铁律

1. 不知道就说不知道，绝不编造
2. 区分"我确定"vs"我推测"vs"我不知道"，用信号词标注
3. 关于自己的工具和能力，绝不猜测——先查 TOOLS.md
4. 工具描述可能不准确，以 TOOLS.md 为准
5. 涉及具体数据（数字/日期/版本号），必须搜索验证后再回答
```

### 方案三：降低 temperature 参数

```json
{
  "params": {
    "temperature": 0.3
  }
}
```

- `temperature = 1.0`（默认）：更"发散"，不确定时倾向编造看似合理的答案
- `temperature = 0.3`：更"收敛"，倾向选择最高概率的答案，减少随机编造
- 知识管理场景建议 0.3，兼顾准确性和对话自然度

### 方案四：强制链接"规则 → 知识 → 行为"

只有规则没有知识 → AI 知道"不该猜"但说不出正确答案
只有知识没有规则 → AI 可能忽略文档继续按直觉回答
只有规则和知识没有链接 → AI 不知道什么时候该去查文档

**三者必须闭环**：

```
规则：回答自身能力问题时，必须先读 TOOLS.md
  ↓
知识：TOOLS.md 里有经过验证的真实信息
  ↓
行为：AI 先查文档，再回答，有据可依
```

---

## 更深一层的思考

### 这不是 AI 的专属问题

你在公司里遇到过这种情况吗？

- 新人问老员工："这个系统是怎么工作的？"
- 老员工凭记忆回答了一个半年前就改了的架构
- 新人按照这个理解去写代码，上线后出了 bug
- 排查半天，发现是"口口相传的知识"已经过时了

这和 AI 的幻觉本质上是**同一个问题**：
- 老员工的"记忆" ≈ AI 的"工具描述"
- 过时的架构知识 ≈ 标签与现实的偏差
- 新人信了 ≈ 下游被污染

**解决方案也是一样的**：不要信口头描述，去看实际代码/配置/运行状态。

### 一个通用的认知三角

```
原则1: 配置 ≠ 状态  →  你配的 vs 系统跑的
原则2: 假设 ≠ 验证  →  你猜的 vs 你查的
原则3: 描述 ≠ 现实  →  它说的 vs 它做的

唯一可信的：观测到的实际行为。
```

任何时候，当你基于"某个东西声称自己是什么"来做决策时，停下来问一句：

> **"这个信息是来自观测，还是来自描述？"**

如果是描述——去验证它。

---

## 一句话总结

> **不要问"它说它是什么"，要问"它实际做了什么"。**
>
> 标签会骗人，文档会过时，描述会失真。
> 唯一不会骗你的，是你亲眼观测到的实际行为。

---

*作者：大王 | 2026-02-18 | 公众号：持续进化营*
*实战环境：OpenClaw v2026.2.13 + Claude Sonnet 4.5 via OpenRouter + 飞书*
*本文基于真实部署经历提炼，非虚构案例*
